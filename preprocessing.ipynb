{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JYnI2_O6YVwH2Nzn4phWVYxTi2CkJXTD",
      "authorship_tag": "ABX9TyO5wGdpkuQnTT7I9JPAAl8A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import random\n",
        "import gc"
      ],
      "metadata": {
        "id": "DgTs6QrcknVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0HrHzgNXxP5"
      },
      "outputs": [],
      "source": [
        "# загрузка исходного изображения и маски\n",
        "img = cv2.imread('PATH_to_IMAGE')\n",
        "mask = cv2.imread('PATH_to_MASK')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# фрагментация изображения и маски\n",
        "height, width, channels = img.shape\n",
        "cropped_img = img[0:(height // 256), 0:(width // 256)]\n",
        "cropped_mask = mask[0:(height // 256), 0:(width // 256)]\n",
        "img = cropped_img\n",
        "img2 = img\n",
        "mask = cropped_mask\n",
        "mask2 = mask\n",
        "height, width, channels = img.shape\n",
        "W_SIZE  = width // 256\n",
        "H_SIZE = height // 256\n",
        "\n",
        "images = []\n",
        "segms = []\n",
        "for ih in range(H_SIZE ):\n",
        "   for iw in range(W_SIZE ):\n",
        "      x = width/W_SIZE * iw\n",
        "      y = height/H_SIZE * ih\n",
        "      h = (height / H_SIZE)\n",
        "      w = (width / W_SIZE )\n",
        "      img = img[int(y):int(y+h), int(x):int(x+w)]\n",
        "      mask = mask[int(y):int(y+h), int(x):int(x+w)]\n",
        "      images.append(img)\n",
        "      segms.append(mask)\n",
        "      img = img2"
      ],
      "metadata": {
        "id": "-0t4_plaZBmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# аугментация\n",
        "images_aug = []\n",
        "segms_aug = []\n",
        "for i in range(len(images)):\n",
        "  aug_1 = A.HorizontalFlip(p=1)\n",
        "  augmented_1 = aug_1(image=images[i], mask=segms[i])\n",
        "  images_aug.append(images_aug, augmented_1['image'])\n",
        "  segms_aug.append(segms_aug, augmented_1['mask'])\n",
        "  aug_2 = A.VerticalFlip(p=1)\n",
        "  augmented_2 = aug_2(image=images[i], mask=segms[i])\n",
        "  images_aug.append(images_aug, augmented_2['image'])\n",
        "  segms_aug.append(segms_aug, augmented_2['mask'])\n",
        "  aug_3 = A.RandomRotate90(p=1)\n",
        "  augmented_3 = aug_3(image=images[i], mask=segms[i])\n",
        "  images_aug.append(images_aug, augmented_3['image'])\n",
        "  segms_aug.append(segms_aug, augmented_3['mask'])\n",
        "  aug_4 = A.Transpose(p=1)\n",
        "  augmented_4 = aug_4(image=images[i], mask=segms[i])\n",
        "  images_aug.append(images_aug, augmented_4['image'])\n",
        "  segms_aug.append(segms_aug, augmented_4['mask'])\n",
        "  aug_5 = A.GridDistortion(p=1)\n",
        "  random.seed(7)\n",
        "  augmented_5 = aug_5(image=images[i], mask=segms[i])\n",
        "  images_aug.append(images_aug, augmented_5['image'])\n",
        "  segms_aug.append(segms_aug, augmented_5['mask'])"
      ],
      "metadata": {
        "id": "UB2g_qiDbCdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.concatenate((np.array(images), np.array(images_aug)), axis=0)\n",
        "masks = np.concatenate((np.array(segms), np.array(segms_aug)), axis=0)"
      ],
      "metadata": {
        "id": "FQ87q9HBcZ3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# перевод масок в категориальный вид\n",
        "def image_cat(image, black_color = 200):\n",
        "  pic = np.array(image)\n",
        "  img = np.zeros((pic.shape[0], pic.shape[1], 1))\n",
        "  np.place(img[ :, :, 0], (pic[ :, :, 0] + pic[ :, :, 1] + pic[ :, :, 2]) < black_color, 0)\n",
        "  np.place(img[ :, :, 0], (pic[ :, :, 0] + pic[ :, :, 1] + pic[ :, :, 2]) >= black_color, 1)\n",
        "  del pic\n",
        "  gc.collect()\n",
        "  return img\n",
        "\n",
        "def images_cat(images):\n",
        "  newImages = []\n",
        "  for t in range(images.shape[0]):\n",
        "    img = images[t].copy()\n",
        "    new_img = image_cat(img)\n",
        "    new_img = np.array(new_img, int)\n",
        "    newImages.append(new_img)\n",
        "    del img, new_img\n",
        "    gc.collect()\n",
        "  newImages = np.array(newImages)\n",
        "  return newImages\n",
        "\n",
        "masks = images_cat(masks).squeeze(3)"
      ],
      "metadata": {
        "id": "rc3zPwe5c3bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# нормализация изображений\n",
        "t1 = A.Compose([\n",
        "    A.Resize(256,256),\n",
        "    A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "datas = []\n",
        "for i in range(len(data)):\n",
        "  aug = t1(image=data[i])\n",
        "  datas.append(aug['image'])\n",
        "datas = np.array(datas)\n",
        "del aug, data\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "NQ2zya6cehUC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}