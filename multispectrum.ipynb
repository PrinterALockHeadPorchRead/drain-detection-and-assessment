{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/7kVMbwbja2B+4r109SOX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_gztWa2mn9I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt4_qU4unLXe"
      },
      "outputs": [],
      "source": [
        "# загрузка фрагментов 256х256 изображений и масок\n",
        "imgs = np.load('PATH_to_imgs')\n",
        "masks = np.load('PATH_tp_masks')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# аугментация снимков и масок\n",
        "imgs_aug = []\n",
        "masks_aug = []\n",
        "import albumentations as A\n",
        "import random\n",
        "for i in range(len(imgs)):\n",
        "  augmented = A.HorizontalFlip(p=1)(image=imgs[i], mask=masks[i])\n",
        "  imgs_aug.append(augmented['image'])\n",
        "  masks_aug.append(augmented['mask'])\n",
        "  augmented = A.VerticalFlip(p=1)(image=imgs[i], mask=masks[i])\n",
        "  imgs_aug.append(augmented['image'])\n",
        "  masks_aug.append(augmented['mask'])\n",
        "  augmented = A.Transpose(p=1)(image=imgs[i], mask=masks[i])\n",
        "  imgs_aug.append(augmented['image'])\n",
        "  masks_aug.append(augmented['mask'])\n",
        "  augmented = A.RandomRotate90(p=1)(image=imgs[i], mask=masks[i])\n",
        "  imgs_aug.append(augmented['image'])\n",
        "  masks_aug.append(augmented['mask'])\n",
        "  random.seed(7)\n",
        "  augmented = A.ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)(image=imgs[i], mask=masks[i])\n",
        "  imgs_aug.append(augmented['image'])\n",
        "  masks_aug.append(augmented['mask'])\n",
        "  random.seed(7)\n",
        "  augmented = A.GridDistortion(p=1)(image=imgs[i], mask=masks[i])\n",
        "  imgs_aug.append(augmented['image'])\n",
        "  masks_aug.append(augmented['mask'])\n",
        "  random.seed(7)\n",
        "  augmented = A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)(image=imgs[i], mask=masks[i])\n",
        "  imgs_aug.append(augmented['image'])\n",
        "  masks_aug.append(augmented['mask'])\n",
        "imgs = np.concatenate((imgs, np.array(imgs_aug)), axis = 0)\n",
        "masks = np.concatenate((masks, np.array(masks_aug)), axis = 0)"
      ],
      "metadata": {
        "id": "G8bZo5uO9mf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# перевод масок в категориальный вид\n",
        "def image_cat(image, class_num, black_color = 128):\n",
        "  pic = np.array(image)\n",
        "  img = np.zeros((pic.shape[0], pic.shape[1], class_num))\n",
        "  np.place(img[ :, :, 0], pic[ :, :, 0] >= black_color, 1)\n",
        "  np.place(img[ :, :, 0], pic[ :, :, 2] >= black_color, 2)\n",
        "  return img\n",
        "\n",
        "segms = []\n",
        "for i in range(len(masks)):\n",
        "  segms.append(image_cat(masks[i], 1, black_color = 128))\n",
        "segms = np.array(segms, int).squeeze(3)"
      ],
      "metadata": {
        "id": "l3sxBRZJna5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# разделение на выборки и загрузка датасетов\n",
        "ix = np.random.choice(len(imgs), len(imgs), False)\n",
        "tr, ts = np.split(ix, ['boundary sample'])\n",
        "print(len(tr), len(ts))\n",
        "\n",
        "train_batch = torch.utils.data.DataLoader(list(zip(np.rollaxis(imgs[tr], 3, 1), segms[tr])),\n",
        "                                          batch_size=8, shuffle=True, pin_memory=True)\n",
        "\n",
        "test_batch = torch.utils.data.DataLoader(list(zip(np.rollaxis(imgs[ts], 3, 1), segms[ts])),\n",
        "                                         batch_size=8, shuffle=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "R-oRxHrMoNtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# архитектура модели\n",
        "class unet_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        input_nbr = 5\n",
        "        num_ch = 64\n",
        "        batchNorm_momentum = 0.1\n",
        "\n",
        "        self.enc_conv0 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_nbr, out_channels = num_ch, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch, out_channels=num_ch, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pool0 = nn.MaxPool2d(kernel_size = 2, return_indices = False)\n",
        "\n",
        "        self.enc_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = num_ch, out_channels = num_ch*2, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*2, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch*2, out_channels=num_ch*2, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*2, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 2, return_indices = False)\n",
        "\n",
        "        self.enc_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels= num_ch*2, out_channels=num_ch*4, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*4, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch*4, out_channels=num_ch*4, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*4, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 2, return_indices = False)\n",
        "\n",
        "        self.enc_conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_ch*4, out_channels=num_ch*8, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*8, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch*8, out_channels=num_ch*8, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*8, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size = 2, return_indices = False)\n",
        "\n",
        "\n",
        "        self.bottleneck_enc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_ch*8, out_channels=num_ch*16, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*16, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch*16, out_channels=num_ch*8, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*8, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "\n",
        "        self.upsample0 =  nn.Upsample(scale_factor=2)\n",
        "\n",
        "        self.dec_conv0 =  nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_ch*16, out_channels=num_ch*8, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*8, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch*8, out_channels=num_ch*4, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*4, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.upsample1 =  nn.Upsample(scale_factor=2)\n",
        "\n",
        "        self.dec_conv1 =  nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_ch*8, out_channels=num_ch*4, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*4, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch*4, out_channels=num_ch*2, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*2, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.upsample2 =  nn.Upsample(scale_factor=2)\n",
        "\n",
        "        self.dec_conv2 =  nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_ch*4, out_channels=num_ch*2, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch*2, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch*2, out_channels=num_ch, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch, momentum= batchNorm_momentum),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.upsample3 = nn.Upsample(scale_factor=2)\n",
        "\n",
        "        self.dec_conv3 =  nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_ch*2, out_channels=num_ch, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch, out_channels=num_ch, kernel_size=3, padding = (1,1)),\n",
        "            nn.BatchNorm2d(num_ch, momentum= batchNorm_momentum),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=num_ch, out_channels=3, kernel_size=1)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        e0 = self.enc_conv0(x)\n",
        "        e1 = self.pool0(e0)\n",
        "        e2 = self.enc_conv1(e1)\n",
        "        e3 = self.pool1(e2)\n",
        "        e4 = self.enc_conv2(e3)\n",
        "        e5 = self.pool2(e4)\n",
        "        e6 = self.enc_conv3(e5)\n",
        "        e7 = self.pool3(e6)\n",
        "\n",
        "        b = self.bottleneck_enc(e7)\n",
        "\n",
        "        d0 = self.upsample0(b)\n",
        "        d0 = self.dec_conv0(torch.cat((d0,e6), dim =1))\n",
        "        d1 = self.upsample1(d0)\n",
        "        d1 = self.dec_conv1(torch.cat((d1,e4), dim =1))\n",
        "        d2 = self.upsample2(d1)\n",
        "        d2 = self.dec_conv2(torch.cat((d2,e2), dim =1))\n",
        "        d3 = self.upsample3(d2)\n",
        "        d3 = self.dec_conv3(torch.cat((d3,e0), dim =1))\n",
        "        return d3"
      ],
      "metadata": {
        "id": "czYQgp3ooiyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# инициализация модели\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = unet_model().to(DEVICE)\n",
        "summary(model, (5, 256, 256))"
      ],
      "metadata": {
        "id": "9p9ELAfcoapG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# настройка параметров обучения\n",
        "LEARNING_RATE = 1e-4\n",
        "num_epochs = 50\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "aAztOGEJopX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучение модели\n",
        "history = {\"epochs\": np.arange(num_epochs)+1, \"score\": [], \"loss\": []}\n",
        "for epoch in range(num_epochs):\n",
        "    dice_score = 0\n",
        "    iou_score = 0\n",
        "    loop = tqdm(enumerate(train_batch),total=len(train_batch))\n",
        "    for batch_idx, (data, targets) in loop:\n",
        "        data = data.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "        targets = targets.type(torch.long)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "            softmax = nn.Softmax(dim=1)\n",
        "            preds = torch.argmax(softmax(model(data)),axis=1)\n",
        "            dice_score += (2 * (preds * targets).sum()) / ((preds + targets).sum() + 1e-8)\n",
        "            iou_score += (((preds & targets).float().sum((1, 2)) + 1e-8) / ((preds | targets).float().sum((1, 2)) + 1e-8)).mean().item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "    avg_loss = 1 - (dice_score / len(loop))\n",
        "    avg_score = iou_score/ len(loop)\n",
        "    print('loss: %f' % avg_loss)\n",
        "    print('score: %f' % avg_score)\n",
        "    print('epoch: %f'% epoch)\n",
        "    history[\"score\"].append(avg_score)\n",
        "    history[\"loss\"].append(avg_loss)"
      ],
      "metadata": {
        "id": "QkDasfJgoskJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сохранение модели\n",
        "model_scripted = torch.jit.script(model)\n",
        "model_scripted.save('PATH_to_MODEL')"
      ],
      "metadata": {
        "id": "Ek10dma8pFwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вычисление метрик на выборках\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    iou_score = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.to(DEVICE)\n",
        "            softmax = nn.Softmax(dim=1)\n",
        "            preds = torch.argmax(softmax(model(x)),axis=1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            dice_score += (2 * (preds * y).sum()) / ((preds + y).sum() + 1e-8)\n",
        "            iou_score += (((preds & y).float().sum((1, 2)) + 1e-8) / ((preds | y).float().sum((1, 2)) + 1e-8)).mean().item()\n",
        "\n",
        "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
        "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
        "    print(f\"IoU score: {iou_score/len(loader)}\")\n",
        "    model.train()\n",
        "\n",
        "print(check_accuracy(train_batch, model))\n",
        "print(check_accuracy(test_batch, model))"
      ],
      "metadata": {
        "id": "5vWOpyXAouBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# построение графиков обучения\n",
        "def make_graph(history, model_name, loss_name):\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (14, 7))\n",
        "    x = history[\"epochs\"]\n",
        "    loss_train = history[\"loss\"]\n",
        "    score_train = history[\"score\"]\n",
        "    ax[0].plot(x, loss_train, label = \"train\", color = \"red\")\n",
        "    ax[0].legend(fontsize = 14)\n",
        "    ax[0].grid(linestyle = \"--\")\n",
        "    ax[0].tick_params(labelsize = 14)\n",
        "    ax[0].set_xlabel(\"epoch\", fontsize = 14)\n",
        "    ax[0].set_ylabel(\"loss\", fontsize = 14)\n",
        "    ax[0].set_title(\"Loss vs epoch\", fontsize = 16)\n",
        "    ax[0].set_xlim(left = 0, right = x.max())\n",
        "    ax[0].set_ylim(bottom = 0)\n",
        "    ax[1].plot(x, score_train, label = \"train\", color = \"blue\")\n",
        "    ax[1].legend(fontsize = 14)\n",
        "    ax[1].grid(linestyle = \"--\")\n",
        "    ax[1].tick_params(labelsize = 14)\n",
        "    ax[1].set_xlabel(\"epoch\", fontsize = 14)\n",
        "    ax[1].set_ylabel(\"score\", fontsize = 14)\n",
        "    ax[1].set_title(\"Score vs epoch\", fontsize = 16)\n",
        "    ax[1].set_xlim(left = 0, right = x.max())\n",
        "    ax[1].set_ylim(bottom = 0)\n",
        "    plt.suptitle(f\"Model = {model_name}, loss = {loss_name}\", fontsize = 18, y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for i in range(len(history['loss'])):\n",
        "  history['loss'][i] = history['loss'][i].item()\n",
        "make_graph(history, \"MODEL_NAME\", \"LOSS_NAME\")"
      ],
      "metadata": {
        "id": "WrMq2UDbpfr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}